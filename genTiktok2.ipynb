{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUqTZ4bpYyD87oc2RUsuwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakyo888/public/blob/main/genTiktok2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount google drive and define DIRs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ai_tiktok\"   # ç”Ÿæˆç‰©ãƒ•ã‚©ãƒ«ãƒ€\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ai_tiktok/audio_segments\" # audio output\n",
        "import os, pathlib; pathlib.Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
        "print(\"Files will be saved under\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQfuf33Jf96p",
        "outputId": "3157dc55-c260-42e3-810e-66c4eecd7ebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files will be saved under /content/drive/MyDrive/ai_tiktok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ”‘ Input API key for Gemini\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Use Colab's Secrets Manager to store your API key\n",
        "# Add your API key to the Secrets Manager under the name 'GOOGLE_API_KEY'\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# You can optionally use getpass for interactive input if not using Secrets Manager,\n",
        "# but Secrets Manager is recommended for security and persistence.\n",
        "# import getpass\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ksB0D4Q4gFal"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title pip and apt-get\n",
        "!pip -q install feedparser gTTS\n",
        "!apt-get -y install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "w9r27gU2CmUp",
        "outputId": "b1b6a656-3cfa-4504-9e8c-3d48ef783e35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ“° Generate news script into script.json\n",
        "import google.generativeai as genai, feedparser, datetime, re, json, textwrap, pathlib\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "MODEL = \"gemini-2.0-flash\"\n",
        "\n",
        "RSS = [\n",
        "  \"https://www.theverge.com/rss/index.xml\",\n",
        "  \"https://feeds.arstechnica.com/arstechnica/technology-lab\",\n",
        "  \"https://generativeai.substack.com/feed\",\n",
        "  \"https://news.yahoo.co.jp/rss/media/techcrunch/all.xml\",\n",
        "]\n",
        "KEYWORDS = re.compile(r\"(ç”Ÿæˆ|generative|AI|LLM)\", re.I)\n",
        "WEEK = datetime.timedelta(days=7)\n",
        "now  = datetime.datetime.now(datetime.timezone.utc)\n",
        "entries = []\n",
        "\n",
        "for url in RSS:\n",
        "  for e in feedparser.parse(url).entries:\n",
        "    if not hasattr(e,\"published_parsed\"): continue\n",
        "    pub = datetime.datetime(*e.published_parsed[:6], tzinfo=datetime.timezone.utc)\n",
        "    if now-pub>WEEK: continue\n",
        "    if KEYWORDS.search(e.title) or KEYWORDS.search(getattr(e,\"summary\",\"\")):\n",
        "      entries.append(e)\n",
        "\n",
        "titles = [e.title for e in entries][:10] or [\"No hot AI news this week\"]\n",
        "\n",
        "prompt = textwrap.dedent(f\"\"\"\n",
        "  ä»¥ä¸‹ã® AI ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’ 5 ãƒˆãƒ”ãƒƒã‚¯ãƒ»å„9ç§’ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®\n",
        "  TikTok å°æœ¬(JSON)ã«ã—ã¦ãã ã•ã„ã€‚visual_suggestion ã‚‚å«ã‚ã¦ã€‚\n",
        "  ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n",
        "  {chr(10).join('- '+t for t in titles)}\n",
        "\"\"\").strip()\n",
        "\n",
        "resp = genai.GenerativeModel(MODEL).generate_content(\n",
        "        prompt,\n",
        "        generation_config={\"temperature\":0.7})\n",
        "\n",
        "print(\"Raw model response text:\")\n",
        "print(resp.text)\n",
        "\n",
        "# Attempt to extract and parse the JSON array part from the response text more robustly\n",
        "script = None\n",
        "try:\n",
        "    # Remove markdown code block syntax\n",
        "    json_string = resp.text.strip()\n",
        "    if json_string.startswith(\"```json\"):\n",
        "        json_string = json_string[len(\"```json\"):].strip()\n",
        "    if json_string.endswith(\"```\"):\n",
        "        json_string = json_string[:-len(\"```\")].strip()\n",
        "\n",
        "    # Attempt to parse the cleaned string as JSON\n",
        "    script = {\"tiktok_script\": json.loads(json_string)} # Assume it's a list and wrap it\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Initial JSON decoding failed: {e}\")\n",
        "    print(\"Attempting to find and parse JSON array within the text.\")\n",
        "    # If initial parsing fails, try to find the JSON array structure\n",
        "    json_start = json_string.find('[')\n",
        "    json_end = json_string.rfind(']')\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_string_to_parse = json_string[json_start : json_end + 1]\n",
        "        try:\n",
        "            script = {\"tiktok_script\": json.loads(json_string_to_parse)} # Wrap the list in a dictionary\n",
        "        except json.JSONDecodeError as inner_e:\n",
        "             print(f\"Error decoding extracted JSON array: {inner_e}\")\n",
        "             print(\"Extracted string attempting to parse:\")\n",
        "             print(json_string_to_parse)\n",
        "             raise # Re-raise the inner exception\n",
        "    else:\n",
        "        print(\"Could not find a valid JSON array structure in the model response after cleaning.\")\n",
        "        raise # Re-raise the initial exception or a new ValueError\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error extracting JSON structure: {e}\")\n",
        "    print(\"Model response text (again for clarity):\")\n",
        "    print(resp.text)\n",
        "    raise # Re-raise the exception\n",
        "\n",
        "if script is None:\n",
        "     raise ValueError(\"Failed to extract and parse JSON from model response.\")\n",
        "\n",
        "\n",
        "path_script = pathlib.Path(OUTPUT_DIR)/\"script.json\"\n",
        "path_script.write_text(json.dumps(script,ensure_ascii=False,indent=2))\n",
        "print(\"âœ… script.json saved:\", path_script)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "collapsed": true,
        "id": "WOgjp5vkVuhs",
        "outputId": "3d8275ec-4395-4a50-c952-2bf5a4308eb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw model response text:\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"topic\": \"ãƒ‡ã‚¶ã‚¤ãƒ³æ¥­ç•Œã«æ¿€éœ‡ï¼Figmaä¸Šå ´ã¸\",\n",
            "    \"narration\": \"ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«FigmaãŒã¤ã„ã«ä¸Šå ´ï¼ãƒ‡ã‚¶ã‚¤ãƒ³æ¥­ç•Œã«æ›´ãªã‚‹é©æ–°ã‚’ã‚‚ãŸã‚‰ã™ã‹ï¼Ÿä»Šå¾Œã®å‹•å‘ã«æ³¨ç›®ã€‚\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"Figmaã®ãƒ­ã‚´ã¨æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‚èˆˆå¥®ã‚’è¡¨ã™BGMã€‚\"\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"Xã€AIãƒœãƒƒãƒˆã«ã‚ˆã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒãƒ¼ãƒˆ\",\n",
            "    \"narration\": \"XãŒAIãƒœãƒƒãƒˆã«ã‚ˆã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒãƒ¼ãƒˆã‚’è§£ç¦ï¼èª¤æƒ…å ±ã®æ‹¡æ•£ã‚’é˜²ãæ–°ãŸãªè©¦ã¿ã€‚åŠ¹æœã¯ã„ã‹ã«ï¼Ÿ\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"Xã®ãƒ­ã‚´ã¨AIãƒœãƒƒãƒˆã®ã‚¢ã‚¤ã‚³ãƒ³ã€‚æ„è¦‹ãŒé£›ã³äº¤ã†ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚\"\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"Ultra Mobileã€ãƒ‡ãƒ¼ã‚¿å®¹é‡å¢—é‡ï¼\",\n",
            "    \"narration\": \"Ultra MobileãŒãƒ‡ãƒ¼ã‚¿å®¹é‡ã‚’å¢—é‡ï¼ã—ã‹ã‚‚ä¾¡æ ¼æ®ãˆç½®ãï¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯å¬‰ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‚ä¹—ã‚Šæ›ãˆæ¤œè¨ã®ãƒãƒ£ãƒ³ã‚¹ï¼Ÿ\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"Ultra Mobileã®ãƒ­ã‚´ã¨ã‚¹ãƒãƒ›ã®ç”»é¢ã€‚é€šä¿¡é€Ÿåº¦ãŒé€Ÿããªã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚\"\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"Grammarlyã€AIç”Ÿç”£æ€§ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸\",\n",
            "    \"narration\": \"GrammarlyãŒAIã‚’æ´»ç”¨ã—ãŸç”Ÿç”£æ€§ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ç›®æŒ‡ã™ï¼æ–‡ç« æ ¡æ­£ã ã‘ã˜ã‚ƒãªã„ã€æ–°ãŸãªå¯èƒ½æ€§ã«æœŸå¾…ã€‚\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"Grammarlyã®ãƒ­ã‚´ã¨ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã€‚æ–‡ç« ä½œæˆãŒã‚¹ãƒ ãƒ¼ã‚ºã«ãªã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚\"\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"Anthropicã¨AIæ™‚ä»£ã®Flashã‚²ãƒ¼ãƒ \",\n",
            "    \"narration\": \"AnthropicãŒAIã§Flashã‚²ãƒ¼ãƒ ã®ç²¾ç¥ã‚’å†ç¾ï¼æ‡ã‹ã—ã•ã¨æ–°ã—ã•ãŒèåˆã—ãŸã€AIã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆã®æœªæ¥ã€‚\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"æ‡ã‹ã—ã„Flashã‚²ãƒ¼ãƒ ã®ç”»é¢ã¨Anthropicã®ãƒ­ã‚´ã€‚æœªæ¥çš„ãªUIã€‚\"\n",
            "  },\n",
            "    {\n",
            "    \"topic\": \"Anthropicã€æ›¸ç±ã‚’ç ´å£Šã—ã¦AIãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼Ÿ\",\n",
            "    \"narration\": \"AnthropicãŒAIãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãŸã‚ã€æ•°ç™¾ä¸‡å†Šã®æ›¸ç±ã‚’ç ´å£Šã—ãŸã¨ã®å ±é“ã€‚ãã®å€«ç†çš„ãªå•é¡Œç‚¹ã¨ã¯ï¼Ÿ\",\n",
            "    \"duration\": 9,\n",
            "    \"visual_suggestion\": \"å±±ç©ã¿ã®æ›¸ç±ãŒç ´å£Šã•ã‚Œã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã¨Anthropicã®ãƒ­ã‚´ã€‚ç‚ã®ã‚¢ã‚¤ã‚³ãƒ³ã€‚\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "âœ… script.json saved: /content/drive/MyDrive/ai_tiktok/script.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb56382b",
        "outputId": "47d072b6-c989-4bd3-b5bf-6981531c01f1"
      },
      "source": [
        "#@title ğŸ“° Load script.json and extract narration segments\n",
        "import os\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "# Make sure OUTPUT_DIR is defined\n",
        "#OUTPUT_DIR = \"/content/drive/MyDrive/ai_tiktok\"\n",
        "\n",
        "# Step 1: Load script.json\n",
        "script_file_path = os.path.join(OUTPUT_DIR, \"script.json\")\n",
        "with open(script_file_path, 'r') as f:\n",
        "    script_data = json.load(f)\n",
        "\n",
        "print(\"âœ… script_data loaded successfully\")\n",
        "\n",
        "# Step 2: Extract the 'tiktok_script' list\n",
        "topics_dict = script_data.get(\"tiktok_script\", {})\n",
        "\n",
        "# If the structure is nested again (double-wrapped), fix it\n",
        "if isinstance(topics_dict, dict) and \"tiktok_script\" in topics_dict:\n",
        "    topic_list = topics_dict[\"tiktok_script\"]\n",
        "elif isinstance(topics_dict, list):\n",
        "    topic_list = topics_dict\n",
        "else:\n",
        "    raise ValueError(\"âŒ Unexpected structure in script_data['tiktok_script'].\")\n",
        "\n",
        "# Step 3: Extract narration texts\n",
        "narration_texts = []\n",
        "\n",
        "for topic_idx, topic in enumerate(topic_list):\n",
        "    if not isinstance(topic, dict):\n",
        "        print(f\"âš ï¸ Topic {topic_idx} is not a dict â€” skipping\")\n",
        "        continue\n",
        "\n",
        "    text = topic.get(\"narration\")\n",
        "    if text:\n",
        "        narration_texts.append(text)\n",
        "    else:\n",
        "        print(f\"âš ï¸ Missing narration in topic {topic_idx}\")\n",
        "\n",
        "# save narration text file\n",
        "merged_narration_texts = \" \".join(narration_texts)\n",
        "narration_file_path = os.path.join(OUTPUT_DIR, \"narratin_text.txt\")\n",
        "with open(narration_file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(merged_narration_texts)\n",
        "\n",
        "print(f\"âœ… Extracted {len(narration_texts)} narration segments.\")\n",
        "\n",
        "# Optional: Preview the narrations\n",
        "for i, t in enumerate(narration_texts[:3]):\n",
        "    print(f\"{i+1}. {t}\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… script_data loaded successfully\n",
            "âœ… Extracted 6 narration segments.\n",
            "1. ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«FigmaãŒã¤ã„ã«ä¸Šå ´ï¼ãƒ‡ã‚¶ã‚¤ãƒ³æ¥­ç•Œã«æ›´ãªã‚‹é©æ–°ã‚’ã‚‚ãŸã‚‰ã™ã‹ï¼Ÿä»Šå¾Œã®å‹•å‘ã«æ³¨ç›®ã€‚\n",
            "2. XãŒAIãƒœãƒƒãƒˆã«ã‚ˆã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒãƒ¼ãƒˆã‚’è§£ç¦ï¼èª¤æƒ…å ±ã®æ‹¡æ•£ã‚’é˜²ãæ–°ãŸãªè©¦ã¿ã€‚åŠ¹æœã¯ã„ã‹ã«ï¼Ÿ\n",
            "3. Ultra MobileãŒãƒ‡ãƒ¼ã‚¿å®¹é‡ã‚’å¢—é‡ï¼ã—ã‹ã‚‚ä¾¡æ ¼æ®ãˆç½®ãï¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯å¬‰ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‚ä¹—ã‚Šæ›ãˆæ¤œè¨ã®ãƒãƒ£ãƒ³ã‚¹ï¼Ÿ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "da1bad6b",
        "outputId": "517bfe1f-d166-4579-f4f2-47a910af7298"
      },
      "source": [
        "#@title Generate audio for each text segment using gTTS and store the generated audio objects or paths.\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "audio_segments = []\n",
        "output_audio_dir = os.path.join(OUTPUT_DIR, \"audio_segments\")\n",
        "os.makedirs(output_audio_dir, exist_ok=True)\n",
        "\n",
        "for i, text in enumerate(narration_texts):\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang='ja', slow=False)\n",
        "        audio_filename = f\"segment_{i:03d}.mp3\"\n",
        "        audio_filepath = os.path.join(output_audio_dir, audio_filename)\n",
        "        tts.save(audio_filepath)\n",
        "        audio_segments.append(audio_filepath)\n",
        "        print(f\"âœ… Generated audio for segment {i}: {audio_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio for segment {i}: {text} - {e}\")\n",
        "        # Optionally, append None or handle the error as needed\n",
        "        audio_segments.append(None)\n",
        "\n",
        "print(f\"\\nGenerated {len(audio_segments)} audio files.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Generated audio for segment 0: segment_000.mp3\n",
            "âœ… Generated audio for segment 1: segment_001.mp3\n",
            "âœ… Generated audio for segment 2: segment_002.mp3\n",
            "âœ… Generated audio for segment 3: segment_003.mp3\n",
            "âœ… Generated audio for segment 4: segment_004.mp3\n",
            "âœ… Generated audio for segment 5: segment_005.mp3\n",
            "\n",
            "Generated 6 audio files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "71a938bd",
        "outputId": "75f1f72a-4d37-4eb7-f572-8b34cbf7ffcd"
      },
      "source": [
        "#@title Concatenate Audio Files\n",
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Set working directory to folder containing audio segments\n",
        "os.chdir(AUDIO_DIR)\n",
        "print(\"ğŸ” Working directory:\", os.getcwd())\n",
        "\n",
        "# Load all .mp3 files\n",
        "audio_segments = sorted(glob.glob(\"*.mp3\"))\n",
        "print(f\"ğŸ§ Found {len(audio_segments)} audio segments.\")\n",
        "\n",
        "combined_narration = AudioSegment.empty()\n",
        "pause_duration = 500  # milliseconds\n",
        "\n",
        "for i, audio_path in enumerate(audio_segments):\n",
        "    if audio_path and os.path.exists(audio_path):\n",
        "        try:\n",
        "            segment_audio = AudioSegment.from_file(audio_path, format=\"mp3\")\n",
        "            combined_narration += segment_audio\n",
        "            if i < len(audio_segments) - 1:\n",
        "                combined_narration += AudioSegment.silent(duration=pause_duration)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {audio_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Skipping missing file: {audio_path}\")\n",
        "\n",
        "# Output combined audio\n",
        "output_combined_audio_path = os.path.join(OUTPUT_DIR, \"final_narration.mp3\")\n",
        "\n",
        "if len(combined_narration) == 0:\n",
        "    print(\"âš ï¸ No audio was combined. Output will be empty.\")\n",
        "else:\n",
        "    try:\n",
        "        combined_narration.export(output_combined_audio_path, format=\"mp3\")\n",
        "        print(f\"âœ… Narration saved: {output_combined_audio_path} ({combined_narration.duration_seconds:.1f} sec)\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error exporting audio: {e}\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Working directory: /content/drive/MyDrive/ai_tiktok/audio_segments\n",
            "ğŸ§ Found 6 audio segments.\n",
            "âœ… Narration saved: /content/drive/MyDrive/ai_tiktok/final_narration.mp3 (69.1 sec)\n"
          ]
        }
      ]
    }
  ]
}