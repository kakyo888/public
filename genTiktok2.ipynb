{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcl54zTLTtZRk14rQuNmAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakyo888/public/blob/main/genTiktok2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount google drive and define DIRs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ai_tiktok\"   # ç”Ÿæˆç‰©ãƒ•ã‚©ãƒ«ãƒ€\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ai_tiktok/audio_segments\" # audio output\n",
        "import os, pathlib; pathlib.Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
        "print(\"Files will be saved under\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQfuf33Jf96p",
        "outputId": "9020a0ab-851a-498e-a478-f349487059ef",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files will be saved under /content/drive/MyDrive/ai_tiktok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ”‘ Input API key for Gemini\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Use Colab's Secrets Manager to store your API key\n",
        "# Add your API key to the Secrets Manager under the name 'GOOGLE_API_KEY'\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# You can optionally use getpass for interactive input if not using Secrets Manager,\n",
        "# but Secrets Manager is recommended for security and persistence.\n",
        "# import getpass\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")"
      ],
      "metadata": {
        "id": "ksB0D4Q4gFal",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title pip and apt-get\n",
        "!pip -q install feedparser gTTS\n",
        "!apt-get -y install ffmpeg"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "w9r27gU2CmUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2daa5de-da67-41c8-e44d-9d8dcdfd87b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ“° Generate news script into script.json\n",
        "import google.generativeai as genai, feedparser, datetime, re, json, textwrap, pathlib\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "MODEL = \"gemini-2.0-flash\"\n",
        "\n",
        "RSS = [\n",
        "  \"https://www.theverge.com/rss/index.xml\",\n",
        "  \"https://feeds.arstechnica.com/arstechnica/technology-lab\",\n",
        "  \"https://generativeai.substack.com/feed\",\n",
        "  \"https://news.yahoo.co.jp/rss/media/techcrunch/all.xml\",\n",
        "]\n",
        "KEYWORDS = re.compile(r\"(ç”Ÿæˆ|generative|AI|LLM)\", re.I)\n",
        "WEEK = datetime.timedelta(days=7)\n",
        "now  = datetime.datetime.now(datetime.timezone.utc)\n",
        "entries = []\n",
        "\n",
        "for url in RSS:\n",
        "  for e in feedparser.parse(url).entries:\n",
        "    if not hasattr(e,\"published_parsed\"): continue\n",
        "    pub = datetime.datetime(*e.published_parsed[:6], tzinfo=datetime.timezone.utc)\n",
        "    if now-pub>WEEK: continue\n",
        "    if KEYWORDS.search(e.title) or KEYWORDS.search(getattr(e,\"summary\",\"\")):\n",
        "      entries.append(e)\n",
        "\n",
        "titles = [e.title for e in entries][:10] or [\"No hot AI news this week\"]\n",
        "\n",
        "prompt = textwrap.dedent(f\"\"\"\n",
        "  ä»¥ä¸‹ã® AI ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’ 5 ãƒˆãƒ”ãƒƒã‚¯ãƒ»å„9ç§’ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®\n",
        "  TikTok å°æœ¬(JSON)ã«ã—ã¦ãã ã•ã„ã€‚visual_suggestion ã‚‚å«ã‚ã¦ã€‚\n",
        "  ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n",
        "  {chr(10).join('- '+t for t in titles)}\n",
        "\"\"\").strip()\n",
        "\n",
        "resp = genai.GenerativeModel(MODEL).generate_content(\n",
        "        prompt,\n",
        "        generation_config={\"temperature\":0.7})\n",
        "\n",
        "print(\"Raw model response text:\")\n",
        "print(resp.text)\n",
        "\n",
        "# Attempt to extract and parse the JSON array part from the response text more robustly\n",
        "script = None\n",
        "try:\n",
        "    # Remove markdown code block syntax\n",
        "    json_string = resp.text.strip()\n",
        "    if json_string.startswith(\"```json\"):\n",
        "        json_string = json_string[len(\"```json\"):].strip()\n",
        "    if json_string.endswith(\"```\"):\n",
        "        json_string = json_string[:-len(\"```\")].strip()\n",
        "\n",
        "    # Attempt to parse the cleaned string as JSON\n",
        "    script = {\"tiktok_script\": json.loads(json_string)} # Assume it's a list and wrap it\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Initial JSON decoding failed: {e}\")\n",
        "    print(\"Attempting to find and parse JSON array within the text.\")\n",
        "    # If initial parsing fails, try to find the JSON array structure\n",
        "    json_start = json_string.find('[')\n",
        "    json_end = json_string.rfind(']')\n",
        "    if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "        json_string_to_parse = json_string[json_start : json_end + 1]\n",
        "        try:\n",
        "            script = {\"tiktok_script\": json.loads(json_string_to_parse)} # Wrap the list in a dictionary\n",
        "        except json.JSONDecodeError as inner_e:\n",
        "             print(f\"Error decoding extracted JSON array: {inner_e}\")\n",
        "             print(\"Extracted string attempting to parse:\")\n",
        "             print(json_string_to_parse)\n",
        "             raise # Re-raise the inner exception\n",
        "    else:\n",
        "        print(\"Could not find a valid JSON array structure in the model response after cleaning.\")\n",
        "        raise # Re-raise the initial exception or a new ValueError\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error extracting JSON structure: {e}\")\n",
        "    print(\"Model response text (again for clarity):\")\n",
        "    print(resp.text)\n",
        "    raise # Re-raise the exception\n",
        "\n",
        "if script is None:\n",
        "     raise ValueError(\"Failed to extract and parse JSON from model response.\")\n",
        "\n",
        "\n",
        "path_script = pathlib.Path(OUTPUT_DIR)/\"script.json\"\n",
        "path_script.write_text(json.dumps(script,ensure_ascii=False,indent=2))\n",
        "print(\"âœ… script.json saved:\", path_script)"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "WOgjp5vkVuhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6261e663-e7f8-48a5-8c8c-7bf4265ebfec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw model response text:\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"topic\": \"é›»æ°—è‡ªå‹•è»Šã®ä¾¡æ ¼å¤‰å‹•\",\n",
            "    \"segments\": [\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"Slate Autoã®é›»æ°—ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒˆãƒ©ãƒƒã‚¯ã€\",\n",
            "        \"visual_suggestion\": \"Slate Autoã®é›»æ°—ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒˆãƒ©ãƒƒã‚¯ã®ç”»åƒã€‚ä»¥å‰ã®ä¾¡æ ¼ã‚’ç¤ºã™ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚‚å…¥ã‚Œã‚‹ã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ä»¥å‰ã¯20,000ãƒ‰ãƒ«ä»¥ä¸‹ã ã£ãŸã®ãŒã€\",\n",
            "        \"visual_suggestion\": \"ä¾¡æ ¼ãŒä¸Šæ˜‡ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã‚°ãƒ©ãƒ•ã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ãªã‚“ã¨å€¤ä¸ŠãŒã‚Šï¼ãã®ç†ç”±ã¯â€¦ï¼Ÿ\",\n",
            "        \"visual_suggestion\": \"ç–‘å•ç¬¦ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‚ãƒ†ã‚­ã‚¹ãƒˆã§ã€Œãƒˆãƒ©ãƒ³ãƒ—ï¼Ÿã€ã¨è¡¨ç¤ºã€‚\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"TikTokå­˜ç¶šã®è£å´\",\n",
            "    \"segments\": [\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"TikTokãŒGoogleã¨Appleã§å­˜ç¶šï¼\",\n",
            "        \"visual_suggestion\": \"TikTokã®ãƒ­ã‚´ã€‚Google Playã‚¹ãƒˆã‚¢ã¨Apple App Storeã®ã‚¢ã‚¤ã‚³ãƒ³ã‚’èƒŒæ™¯ã«ã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ãã®èˆå°è£ã«ã¯ã€èª¬å¾—åŠ›ã®ã‚ã‚‹\",\n",
            "        \"visual_suggestion\": \"æ‰‹ç´™ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚é‡è¦éƒ¨åˆ†ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ã€Œæ‰‹ç´™ã€ã®å­˜åœ¨ãŒã‚ã£ãŸï¼\",\n",
            "        \"visual_suggestion\": \"æ‰‹ç´™ãŒé–‹å°ã•ã‚Œã‚‹ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‚\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"ã‚¢ãƒ¡ãƒªã‚«ã®äºˆç®—æ¡ˆ\",\n",
            "    \"segments\": [\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ã‚¢ãƒ¡ãƒªã‚«è­°ä¼šãŒäºˆç®—æ¡ˆã‚’å¯æ±ºã€‚\",\n",
            "        \"visual_suggestion\": \"ã‚¢ãƒ¡ãƒªã‚«åˆè¡†å›½è­°ä¼šè­°äº‹å ‚ã®ç”»åƒã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"å¤§è¦æ¨¡ãªå¼·åˆ¶é€é‚„ã®æ‹¡å¤§ã€\",\n",
            "        \"visual_suggestion\": \"å¼·åˆ¶é€é‚„ã•ã‚Œã‚‹äººã€…ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ã‚¯ãƒªãƒ¼ãƒ³ã‚¨ãƒãƒ«ã‚®ãƒ¼åœæ»â€¦ï¼Ÿ\",\n",
            "        \"visual_suggestion\": \"é¢¨åŠ›ã‚¿ãƒ¼ãƒ“ãƒ³ãŒæ­¢ã¾ã£ã¦ã„ã‚‹ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‚\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"ãŠæƒé™¤ãƒ­ãƒœãƒƒãƒˆã‚»ãƒ¼ãƒ«æƒ…å ±\",\n",
            "    \"segments\": [\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ä»ŠãŒãŠå¾—ï¼ãŠæƒé™¤ãƒ­ãƒœãƒƒãƒˆ\",\n",
            "        \"visual_suggestion\": \"æ§˜ã€…ãªãŠæƒé™¤ãƒ­ãƒœãƒƒãƒˆã®ç”»åƒãŒæ¬¡ã€…ã¨è¡¨ç¤ºã•ã‚Œã‚‹ã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"æœ€æ–°ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ï¼\",\n",
            "        \"visual_suggestion\": \"ã€ŒSALEã€ã®æ–‡å­—ãŒå¤§ããè¡¨ç¤ºã•ã‚Œã‚‹ã€‚å‰²å¼•ç‡ã‚’è¡¨ç¤ºã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"è³¢ããŠæƒé™¤ã€æ¥½ã€…ç”Ÿæ´»ï¼\",\n",
            "        \"visual_suggestion\": \"ãŠæƒé™¤ãƒ­ãƒœãƒƒãƒˆãŒéƒ¨å±‹ã‚’æƒé™¤ã—ã¦ã„ã‚‹æ§˜å­ã€‚äººç‰©ãŒãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ã„ã‚‹æ§˜å­ã€‚\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"topic\": \"SIMã‚¹ãƒ¯ãƒƒãƒ—è©æ¬ºå¯¾ç­–\",\n",
            "    \"segments\": [\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"AT&TãŒSIMã‚¹ãƒ¯ãƒƒãƒ—è©æ¬ºå¯¾ç­–ï¼\",\n",
            "        \"visual_suggestion\": \"AT&Tã®ãƒ­ã‚´ã€‚SIMã‚«ãƒ¼ãƒ‰ã®ç”»åƒã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ­ãƒƒã‚¯\",\n",
            "        \"visual_suggestion\": \"éµã®ã‚¢ã‚¤ã‚³ãƒ³ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ­ãƒƒã‚¯ã®ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚\"\n",
            "      },\n",
            "      {\n",
            "        \"duration\": 3,\n",
            "        \"narration\": \"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã§å®‰å¿ƒï¼\",\n",
            "        \"visual_suggestion\": \"ç›¾ã®ã‚¢ã‚¤ã‚³ãƒ³ã€‚å®‰å…¨æ€§ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã€‚\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "```\n",
            "âœ… script.json saved: /content/drive/MyDrive/ai_tiktok/script.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "cellView": "form",
        "id": "bb56382b",
        "outputId": "828ecb26-df39-45aa-fd31-931603a7e5ae"
      },
      "source": [
        "#@title ğŸ“° Load script.json and extract narration segments\n",
        "# ğŸ“° Load script.json and extract narration segments\n",
        "import os, json, pathlib\n",
        "\n",
        "# 1) Folder setup â”€ change if needed\n",
        "#OUTPUT_DIR = \"/content/drive/MyDrive/ai_tiktok\"\n",
        "script_path = os.path.join(OUTPUT_DIR, \"script.json\")\n",
        "\n",
        "if not pathlib.Path(script_path).is_file():\n",
        "    raise FileNotFoundError(f\"âŒ {script_path} not found\")\n",
        "\n",
        "# 2) Read JSON\n",
        "with open(script_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    script_data = json.load(f)\n",
        "print(\"âœ… script_data loaded successfully\")\n",
        "\n",
        "# 3) Walk the structure: tiktok_script âœ tiktok_script (list) âœ segments\n",
        "# Corrected access based on actual script_data structure and model output\n",
        "# Access the inner list of topics correctly\n",
        "topics = script_data.get(\"tiktok_script\", {}).get(\"tiktok_script\", [])\n",
        "\n",
        "narration_texts = []\n",
        "# Iterate through each topic in the list\n",
        "for topic_idx, topic in enumerate(topics):\n",
        "    # Access the segments list within each topic dictionary\n",
        "    for seg_idx, seg in enumerate(topic.get(\"segments\", [])):\n",
        "        # The narration text is under the \"narration\" key, not \"text\"\n",
        "        text = seg.get(\"narration\")\n",
        "        if text:\n",
        "            narration_texts.append(text.strip())\n",
        "        else:\n",
        "            print(f\"âš ï¸ Topic {topic_idx} / segment {seg_idx} missing narration text\")\n",
        "\n",
        "\n",
        "if not narration_texts:\n",
        "    raise ValueError(\"âŒ No narration strings found in script.json\")\n",
        "\n",
        "# 4) Save merged narration file\n",
        "out_txt = os.path.join(OUTPUT_DIR, \"narration_text.txt\")\n",
        "with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    # Join narration texts with a space for the combined file\n",
        "    f.write(\" \".join(narration_texts))\n",
        "\n",
        "print(f\"âœ… Extracted {len(narration_texts)} narration segments â†’ {out_txt}\")\n",
        "\n",
        "# 5) Quick preview\n",
        "for i, t in enumerate(narration_texts[:5], 1):\n",
        "    print(f\"{i}. {t}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… script_data loaded successfully\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'get'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-1562491701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Corrected access based on actual script_data structure and model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Access the inner list of topics correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tiktok_script\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tiktok_script\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnarration_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "collapsed": true,
        "cellView": "form",
        "id": "da1bad6b",
        "outputId": "8724a059-5aed-4a02-f4e8-763d0bb75a0c"
      },
      "source": [
        "#@title Generate audio for each text segment using gTTS and store the generated audio objects or paths.\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "audio_segments = []\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "for i, text in enumerate(narration_texts):\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang='ja', slow=False)\n",
        "        audio_filename = f\"segment_{i:03d}.mp3\"\n",
        "        audio_filepath = os.path.join(AUDIO_DIR, audio_filename)\n",
        "        tts.save(audio_filepath)\n",
        "        audio_segments.append(audio_filepath)\n",
        "        print(f\"âœ… Generated audio for segment {i}: {audio_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio for segment {i}: {text} - {e}\")\n",
        "        # Optionally, append None or handle the error as needed\n",
        "        audio_segments.append(None)\n",
        "\n",
        "print(f\"\\nGenerated {len(audio_segments)} audio files.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'narration_texts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2446214098.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarration_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'narration_texts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "71a938bd"
      },
      "source": [
        "#@title Concatenate Audio Files\n",
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Set working directory to folder containing audio segments\n",
        "os.chdir(AUDIO_DIR)\n",
        "print(\"ğŸ” Working directory:\", os.getcwd())\n",
        "\n",
        "# Load all .mp3 files\n",
        "audio_segments = sorted(glob.glob(\"*.mp3\"))\n",
        "print(f\"ğŸ§ Found {len(audio_segments)} audio segments.\")\n",
        "\n",
        "combined_narration = AudioSegment.empty()\n",
        "pause_duration = 500  # milliseconds\n",
        "\n",
        "for i, audio_path in enumerate(audio_segments):\n",
        "    if audio_path and os.path.exists(audio_path):\n",
        "        try:\n",
        "            segment_audio = AudioSegment.from_file(audio_path, format=\"mp3\")\n",
        "            combined_narration += segment_audio\n",
        "            if i < len(audio_segments) - 1:\n",
        "                combined_narration += AudioSegment.silent(duration=pause_duration)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {audio_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Skipping missing file: {audio_path}\")\n",
        "\n",
        "# Output combined audio\n",
        "output_combined_audio_path = os.path.join(OUTPUT_DIR, \"final_narration.mp3\")\n",
        "\n",
        "if len(combined_narration) == 0:\n",
        "    print(\"âš ï¸ No audio was combined. Output will be empty.\")\n",
        "else:\n",
        "    try:\n",
        "        combined_narration.export(output_combined_audio_path, format=\"mp3\")\n",
        "        print(f\"âœ… Narration saved: {output_combined_audio_path} ({combined_narration.duration_seconds:.1f} sec)\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error exporting audio: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Customising visuals\n",
        "    Swap background: Replace ColorClip with VideoFileClip(\"your_stock.mp4\").resize(height=1920) and, if needed, add .fx(mpy.vfx.crop, ...) to keep vertical framing.\n",
        "    Text styles: Change font, fontsize, position (\"center\",\"top\" etc.), or animate with .crossfadein() / .fadein().\n",
        "    B-roll per segment: Instead of one long background, build a list of 15 s stock clips and use the same start/duration logic to line them up behind the captions.\n",
        "'''\n",
        "\n",
        "#@title generate final movie\n",
        "\n",
        "# 1) â”€â”€ USER CONFIG ---------------------------------------------------\n",
        "# NOTE: `OUTPUT_DIR` and `AUDIO_DIR` must already be defined in the notebook:\n",
        "# OUTPUT_DIR = \"/content/drive/MyDrive/ai_tiktok\"\n",
        "# AUDIO_DIR  = \"/content/drive/MyDrive/ai_tiktok/audio_segments\"\n",
        "\n",
        "# Install required libraries\n",
        "!pip install moviepy openai-whisper pysrt pillow tqdm imageio imageio-ffmpeg -q\n",
        "!apt-get -y install ffmpeg\n",
        "\n",
        "try:\n",
        "    OUTPUT_DIR\n",
        "    AUDIO_DIR\n",
        "except NameError as e:\n",
        "    raise NameError(\"âŒ Please run the cell that defines OUTPUT_DIR and AUDIO_DIR first.\") from e\n",
        "\n",
        "import pysrt, whisper, moviepy.editor as mpy\n",
        "import os, pathlib, textwrap\n",
        "\n",
        "MP3_PATH  = os.path.join(OUTPUT_DIR, \"final_narration.mp3\")     # adjust if it lives in AUDIO_DIR\n",
        "WORK_DIR  = os.path.join(OUTPUT_DIR, \"out\")\n",
        "pathlib.Path(WORK_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT_VIDEO = os.path.join(WORK_DIR, \"tiktok_final.mp4\")\n",
        "SRT_PATH  = os.path.splitext(OUT_VIDEO)[0] + \".srt\"\n",
        "FONT_TTF  = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "\n",
        "# Appearance\n",
        "FONT_SIZE, TXT_COLOR, STROKE_W = 70, \"white\", 2\n",
        "BG_COLOR, FPS, WRAP_CHARS      = (0, 0, 0), 30, 30\n",
        "\n",
        "# 2) â”€â”€ Transcribe with Whisper --------------------------------------\n",
        "model    = whisper.load_model(\"base\")\n",
        "result   = model.transcribe(MP3_PATH, fp16=False)\n",
        "segments = result[\"segments\"]\n",
        "\n",
        "# Save captions as SRT\n",
        "srts = pysrt.SubRipFile()\n",
        "for i, seg in enumerate(segments, 1):\n",
        "    srts.append(\n",
        "        pysrt.SubRipItem(\n",
        "            index = i,\n",
        "            start = pysrt.SubRipTime(milliseconds=int(seg[\"start\"]*1000)),\n",
        "            end   = pysrt.SubRipTime(milliseconds=int(seg[\"end\"]  *1000)),\n",
        "            text  = seg[\"text\"].strip()\n",
        "        )\n",
        "    )\n",
        "srts.save(SRT_PATH, encoding=\"utf-8\")\n",
        "print(\"ğŸ“„  SRT saved â†’\", SRT_PATH)\n",
        "\n",
        "# 3) â”€â”€ Build vertical 1080Ã—1920 video -------------------------------\n",
        "audio_clip = mpy.AudioFileClip(MP3_PATH)\n",
        "DURATION   = audio_clip.duration\n",
        "BG_SIZE    = (1080, 1920)\n",
        "\n",
        "bg_clip = mpy.ColorClip(size=BG_SIZE, color=BG_COLOR, duration=DURATION)\n",
        "\n",
        "txt_layers = []\n",
        "for seg in segments:\n",
        "    caption = textwrap.fill(seg[\"text\"].strip(), WRAP_CHARS)\n",
        "    txt = (mpy.TextClip(\n",
        "              caption,\n",
        "              font_size   = FONT_SIZE,\n",
        "              font        = FONT_TTF,\n",
        "              color       = TXT_COLOR,\n",
        "              stroke_color= \"black\",\n",
        "              stroke_width= STROKE_W,\n",
        "              method      = \"pillow\",\n",
        "              size        = (int(BG_SIZE[0]*0.9), None))\n",
        "           .set_position((\"center\", \"bottom\"))\n",
        "           .set_start(seg[\"start\"])\n",
        "           .set_duration(seg[\"end\"] - seg[\"start\"]))\n",
        "    txt_layers.append(txt)\n",
        "\n",
        "final = mpy.CompositeVideoClip([bg_clip, *txt_layers]).set_audio(audio_clip)\n",
        "final.write_videofile(\n",
        "    OUT_VIDEO,\n",
        "    fps         = FPS,\n",
        "    codec       = \"libx264\",\n",
        "    audio_codec = \"aac\",\n",
        "    preset      = \"medium\",\n",
        "    threads     = 4)\n",
        "\n",
        "print(\"âœ…  Finished! TikTok-ready MP4 at:\", OUT_VIDEO)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SSvLfDLzS0P6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}